# -*- coding: utf-8 -*-
"""unet

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-AMJdwzHeCMOr-k0Ml9SmKXScUN8yDN3
"""

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import *
import keras
from keras.layers import *
from keras.optimizers import *
from tensorflow.keras.optimizers import Adam

input_shape = (128, 128, 3)
inputs = Input(shape=input_shape)

# Down 1
c1 = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(inputs)
c1 = BatchNormalization(scale=True)(c1)
c1 = Activation('relu')(c1)
c1 = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(c1)
c1 = BatchNormalization(scale=True)(c1)
c1 = Activation('relu')(c1)
p1 = MaxPooling2D((2, 2))(c1)

# Down 2
c2 = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(p1)
c2 = BatchNormalization(scale=True)(c2)
c2 = Activation('relu')(c2)
c2 = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(c2)
c2 = BatchNormalization(scale=True)(c2)
c2 = Activation('relu')(c2)
p2 = MaxPooling2D((2, 2))(c2)

# Down 3
c3 = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(p2)
c3 = BatchNormalization(scale=True)(c3)
c3 = Activation('relu')(c3)
c3 = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(c3)
c3 = BatchNormalization(scale=True)(c3)
c3 = Activation('relu')(c3)
p3 = MaxPooling2D((2, 2))(c3)

# Down 4
c4 = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(p3)
c4 = BatchNormalization(scale=True)(c4)
c4 = Activation('relu')(c4)
c4 = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(c4)
c4 = BatchNormalization(scale=True)(c4)
c4 = Activation('relu')(c4)
p4 = MaxPooling2D((2, 2))(c4)

# Bottleneck
c5 = Conv2D(1024, (3, 3), padding='same', kernel_initializer='he_normal')(p4)
c5 = BatchNormalization(scale=True)(c5)
c5 = Activation('relu')(c5)
c5 = Conv2D(1024, (3, 3), padding='same', kernel_initializer='he_normal')(c5)
c5 = BatchNormalization(scale=True)(c5)
c5 = Activation('relu')(c5)

# Up 4
u4 = UpSampling2D((2, 2))(c5)
u4 = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal')(u4)
u4 = BatchNormalization(scale=True)(u4)
u4 = Activation('relu')(u4)
u4 = concatenate([c4, u4])
u4 = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(u4)
u4 = BatchNormalization(scale=True)(u4)
u4 = Activation('relu')(u4)
u4 = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(u4)
u4 = BatchNormalization(scale=True)(u4)
u4 = Activation('relu')(u4)

# Up 3
u3 = UpSampling2D((2, 2))(u4)
u3 = Conv2D(256, (2, 2), padding='same', kernel_initializer='he_normal')(u3)
u3 = BatchNormalization(scale=True)(u3)
u3 = Activation('relu')(u3)
u3 = concatenate([c3, u3])
u3 = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(u3)
u3 = BatchNormalization(scale=True)(u3)
u3 = Activation('relu')(u3)
u3 = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(u3)
u3 = BatchNormalization(scale=True)(u3)
u3 = Activation('relu')(u3)

# Up 2
u2 = UpSampling2D((2, 2))(u3)
u2 = Conv2D(128, (2, 2), padding='same', kernel_initializer='he_normal')(u2)
u2 = BatchNormalization(scale=True)(u2)
u2 = Activation('relu')(u2)
u2 = concatenate([c2, u2])
u2 = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(u2)
u2 = BatchNormalization(scale=True)(u2)
u2 = Activation('relu')(u2)
u2 = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(u2)
u2 = BatchNormalization(scale=True)(u2)
u2 = Activation('relu')(u2)

# Up 1
u1 = UpSampling2D((2, 2))(u2)
u1 = Conv2D(64, (2, 2), padding='same', kernel_initializer='he_normal')(u1)
u1 = BatchNormalization(scale=True)(u1)
u1 = Activation('relu')(u1)
u1 = concatenate([c1, u1])
u1 = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(u1)
u1 = BatchNormalization(scale=True)(u1)
u1 = Activation('relu')(u1)
u1 = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(u1)
u1 = BatchNormalization(scale=True)(u1)
u1 = Activation('relu')(u1)

# Output
output = Conv2D(2, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu')(u1)
output = Conv2D(1, (1, 1), activation='sigmoid')(output)

# Model
model = Model(inputs=[inputs], outputs=[output])
model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])